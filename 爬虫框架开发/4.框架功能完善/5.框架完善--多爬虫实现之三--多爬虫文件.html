<!DOCTYPE HTML>
<html lang="en" >
    
    <head>
        
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <title>多爬虫文件实现 | 传智播客python爬虫课程</title>
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="generator" content="GitBook 2.6.7">
        
        
        <meta name="HandheldFriendly" content="true"/>
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
        <meta name="apple-mobile-web-app-capable" content="yes">
        <meta name="apple-mobile-web-app-status-bar-style" content="black">
        <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../../gitbook/images/apple-touch-icon-precomposed-152.png">
        <link rel="shortcut icon" href="../../gitbook/images/favicon.ico" type="image/x-icon">
        
    <link rel="stylesheet" href="../../gitbook/style.css">
    
        
        <link rel="stylesheet" href="../../gitbook/plugins/gitbook-plugin-emphasize/plugin.css">
        
    
        
        <link rel="stylesheet" href="../../gitbook/plugins/gitbook-plugin-prism/prism-solarizedlight.css">
        
    
        
        <link rel="stylesheet" href="../../gitbook/plugins/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.css">
        
    
        
        <link rel="stylesheet" href="../../gitbook/plugins/gitbook-plugin-search/search.css">
        
    
        
        <link rel="stylesheet" href="../../gitbook/plugins/gitbook-plugin-fontsettings/website.css">
        
    
    

        
    
    
    <link rel="next" href="../../爬虫框架开发/4.框架功能完善/6.框架完善--实现多个管道.html" />
    
    
    <link rel="prev" href="../../爬虫框架开发/4.框架功能完善/4.框架完善--多爬虫实现之二--多个解析函数.html" />
    

        
    </head>
    <body>
        
        
    <div class="book"
        data-level="3.3.5"
        data-chapter-title="多爬虫文件实现"
        data-filepath="爬虫框架开发/4.框架功能完善/5.框架完善--多爬虫实现之三--多爬虫文件.md"
        data-basepath="../.."
        data-revision="Wed Jul 18 2018 14:09:40 GMT+0800 (中国标准时间)"
        data-innerlanguage="">
    

<div class="book-summary">
    <nav role="navigation">
        <ul class="summary">
            
            
            
            

            

            
    
        <li class="chapter " data-level="0" data-path="index.html">
            
                
                    <a href="../../index.html">
                
                        <i class="fa fa-check"></i>
                        
                        传智播客python爬虫课程讲义
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="0.1" data-path="爬虫阶段课程介绍/爬虫技术概述.html">
            
                
                    <a href="../../爬虫阶段课程介绍/爬虫技术概述.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>0.1.</b>
                        
                        爬虫技术概述
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="0.2" data-path="爬虫阶段课程介绍/课程介绍.html">
            
                
                    <a href="../../爬虫阶段课程介绍/课程介绍.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>0.2.</b>
                        
                        爬虫阶段课程介绍
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="0.3" data-path="爬虫阶段课程介绍/在课程开始之前.html">
            
                
                    <a href="../../爬虫阶段课程介绍/在课程开始之前.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>0.3.</b>
                        
                        在课程开始之前
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="0.4" data-path="爬虫阶段课程介绍/爬虫课程开发环境参考.html">
            
                
                    <a href="../../爬虫阶段课程介绍/爬虫课程开发环境参考.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>0.4.</b>
                        
                        爬虫提高课程开发环境参考
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1" data-path="爬虫入门/index.html">
            
                
                    <a href="../../爬虫入门/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.</b>
                        
                        爬虫入门
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.1" data-path="爬虫入门/1.爬虫的基础知识/index.html">
            
                
                    <a href="../../爬虫入门/1.爬虫的基础知识/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.1.</b>
                        
                        爬虫的基础知识
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.1.1" data-path="爬虫入门/1.爬虫的基础知识/1.爬虫的基础概念.html">
            
                
                    <a href="../../爬虫入门/1.爬虫的基础知识/1.爬虫的基础概念.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.1.1.</b>
                        
                        爬虫的定义和使用场景
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.1.2" data-path="爬虫入门/1.爬虫的基础知识/2.爬虫的分类和爬虫流程.html">
            
                
                    <a href="../../爬虫入门/1.爬虫的基础知识/2.爬虫的分类和爬虫流程.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.1.2.</b>
                        
                        爬虫的分类和爬虫的流程
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.1.3" data-path="爬虫入门/1.爬虫的基础知识/3.复习http和https.html">
            
                
                    <a href="../../爬虫入门/1.爬虫的基础知识/3.复习http和https.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.1.3.</b>
                        
                        http和https的复习
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.1.4" data-path="爬虫入门/1.爬虫的基础知识/4.字符串相关的复习.html">
            
                
                    <a href="../../爬虫入门/1.爬虫的基础知识/4.字符串相关的复习.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.1.4.</b>
                        
                        字符串相关的复习
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.1.5" data-path="爬虫入门/1.爬虫的基础知识/5.小结.html">
            
                
                    <a href="../../爬虫入门/1.爬虫的基础知识/5.小结.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.1.5.</b>
                        
                        小结
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="爬虫入门/2.requests模块的使用/index.html">
            
                
                    <a href="../../爬虫入门/2.requests模块的使用/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.</b>
                        
                        请求的发送方法
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="爬虫入门/2.requests模块的使用/1.requests模块的基本使用.html">
            
                
                    <a href="../../爬虫入门/2.requests模块的使用/1.requests模块的基本使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.1.</b>
                        
                        requests模块的基本使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="爬虫入门/2.requests模块的使用/2.requests模块的深入使用.html">
            
                
                    <a href="../../爬虫入门/2.requests模块的使用/2.requests模块的深入使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.2.</b>
                        
                        requests模块的深入使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.2.3" data-path="爬虫入门/2.requests模块的使用/3.requests模块处理cookie.html">
            
                
                    <a href="../../爬虫入门/2.requests模块的使用/3.requests模块处理cookie.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.3.</b>
                        
                        requests模块处理cookie
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.2.4" data-path="爬虫入门/2.requests模块的使用/4.requests模块的其他方法.html">
            
                
                    <a href="../../爬虫入门/2.requests模块的使用/4.requests模块的其他方法.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.4.</b>
                        
                        requests的其他方法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.2.5" data-path="爬虫入门/2.requests模块的使用/5.urllib的介绍.html">
            
                
                    <a href="../../爬虫入门/2.requests模块的使用/5.urllib的介绍.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.5.</b>
                        
                        urllib的介绍
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.2.6" data-path="爬虫入门/2.requests模块的使用/6小结.html">
            
                
                    <a href="../../爬虫入门/2.requests模块的使用/6小结.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.6.</b>
                        
                        小结
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="爬虫入门/3.数据提取方法/index.html">
            
                
                    <a href="../../爬虫入门/3.数据提取方法/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.</b>
                        
                        数据提取方法
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="爬虫入门/3.数据提取方法/1.数据提取的概念和数据分类.html">
            
                
                    <a href="../../爬虫入门/3.数据提取方法/1.数据提取的概念和数据分类.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.1.</b>
                        
                        数据提取的概念和数据分类
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="爬虫入门/3.数据提取方法/2.json字符串的数据提取.html">
            
                
                    <a href="../../爬虫入门/3.数据提取方法/2.json字符串的数据提取.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.2.</b>
                        
                        数据提取之json
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="爬虫入门/3.数据提取方法/3.数据提取之正则.html">
            
                
                    <a href="../../爬虫入门/3.数据提取方法/3.数据提取之正则.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.3.</b>
                        
                        数据提取之正则
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.3.4" data-path="爬虫入门/3.数据提取方法/4.xpath和lxml类库.html">
            
                
                    <a href="../../爬虫入门/3.数据提取方法/4.xpath和lxml类库.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.4.</b>
                        
                        数据提取之xpath
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.3.5" data-path="爬虫入门/3.数据提取方法/5.lxml模块的学习.html">
            
                
                    <a href="../../爬虫入门/3.数据提取方法/5.lxml模块的学习.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.5.</b>
                        
                        数据提取之lxml
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.3.6" data-path="爬虫入门/3.数据提取方法/6.beautifulsoup的学习.html">
            
                
                    <a href="../../爬虫入门/3.数据提取方法/6.beautifulsoup的学习.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.6.</b>
                        
                        数据提取之beautifulsoup
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.3.7" data-path="爬虫入门/3.数据提取方法/7.小结.html">
            
                
                    <a href="../../爬虫入门/3.数据提取方法/7.小结.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.7.</b>
                        
                        小结
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2" data-path="爬虫提高/index.html">
            
                
                    <a href="../../爬虫提高/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.</b>
                        
                        爬虫提高
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.1" data-path="爬虫提高/1.高性能爬虫/index.html">
            
                
                    <a href="../../爬虫提高/1.高性能爬虫/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.1.</b>
                        
                        高性能爬虫
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.1.1" data-path="爬虫提高/1.高性能爬虫/1.单线程爬虫.html">
            
                
                    <a href="../../爬虫提高/1.高性能爬虫/1.单线程爬虫.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.1.1.</b>
                        
                        单线程爬虫
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.1.2" data-path="爬虫提高/1.高性能爬虫/2.多线程爬虫.html">
            
                
                    <a href="../../爬虫提高/1.高性能爬虫/2.多线程爬虫.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.1.2.</b>
                        
                        多线程爬虫
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.1.3" data-path="爬虫提高/1.高性能爬虫/3.多进程爬虫.html">
            
                
                    <a href="../../爬虫提高/1.高性能爬虫/3.多进程爬虫.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.1.3.</b>
                        
                        多进程爬虫
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.1.4" data-path="爬虫提高/1.高性能爬虫/4.线程池爬虫.html">
            
                
                    <a href="../../爬虫提高/1.高性能爬虫/4.线程池爬虫.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.1.4.</b>
                        
                        线程池爬虫
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.1.5" data-path="爬虫提高/1.高性能爬虫/5.协程池爬虫.html">
            
                
                    <a href="../../爬虫提高/1.高性能爬虫/5.协程池爬虫.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.1.5.</b>
                        
                        协程池爬虫
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.1.6" data-path="爬虫提高/1.高性能爬虫/6.小结.html">
            
                
                    <a href="../../爬虫提高/1.高性能爬虫/6.小结.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.1.6.</b>
                        
                        小结
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="爬虫提高/2.selenium/index.html">
            
                
                    <a href="../../爬虫提高/2.selenium/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.2.</b>
                        
                        selenium
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.2.1" data-path="爬虫提高/2.selenium/1.无头浏览器的介绍.html">
            
                
                    <a href="../../爬虫提高/2.selenium/1.无头浏览器的介绍.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.2.1.</b>
                        
                        无头浏览器的介绍
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.2.2" data-path="爬虫提高/2.selenium/2.selenium的基本使用.html">
            
                
                    <a href="../../爬虫提高/2.selenium/2.selenium的基本使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.2.2.</b>
                        
                        selenium的基本使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.2.3" data-path="爬虫提高/2.selenium/3.元素定位的方法.html">
            
                
                    <a href="../../爬虫提高/2.selenium/3.元素定位的方法.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.2.3.</b>
                        
                        selenium元素定位的方法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.2.4" data-path="爬虫提高/2.selenium/4.selenium的其他方法.html">
            
                
                    <a href="../../爬虫提高/2.selenium/4.selenium的其他方法.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.2.4.</b>
                        
                        selenium的其他方法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.2.5" data-path="爬虫提高/2.selenium/5.selenium案例.html">
            
                
                    <a href="../../爬虫提高/2.selenium/5.selenium案例.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.2.5.</b>
                        
                        selenium案例
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.2.6" data-path="爬虫提高/2.selenium/6.小结.html">
            
                
                    <a href="../../爬虫提高/2.selenium/6.小结.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.2.6.</b>
                        
                        小结
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.3" data-path="爬虫提高/3.反扒以及解决方案/index.html">
            
                
                    <a href="../../爬虫提高/3.反扒以及解决方案/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.3.</b>
                        
                        反爬以及解决方案
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.3.1" data-path="爬虫提高/3.反扒以及解决方案/1.常见的反扒手段和解决方法.html">
            
                
                    <a href="../../爬虫提高/3.反扒以及解决方案/1.常见的反扒手段和解决方法.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.3.1.</b>
                        
                        常见反爬手段
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.3.2" data-path="爬虫提高/3.反扒以及解决方案/2.打码平台的使用.html">
            
                
                    <a href="../../爬虫提高/3.反扒以及解决方案/2.打码平台的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.3.2.</b>
                        
                        打码平台的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.3.3" data-path="爬虫提高/3.反扒以及解决方案/3.chrome在爬虫中的使用.html">
            
                
                    <a href="../../爬虫提高/3.反扒以及解决方案/3.chrome在爬虫中的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.3.3.</b>
                        
                        chrome在爬虫中的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.3.4" data-path="爬虫提高/3.反扒以及解决方案/4.JS的解析.html">
            
                
                    <a href="../../爬虫提高/3.反扒以及解决方案/4.JS的解析.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.3.4.</b>
                        
                        JS的解析
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.3.5" data-path="爬虫提高/3.反扒以及解决方案/5.小结.html">
            
                
                    <a href="../../爬虫提高/3.反扒以及解决方案/5.小结.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.3.5.</b>
                        
                        小结
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.4" data-path="爬虫提高/4.MONGODB数据库/index.html">
            
                
                    <a href="../../爬虫提高/4.MONGODB数据库/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.4.</b>
                        
                        MONGODB数据库
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.4.1" data-path="爬虫提高/4.MONGODB数据库/1.mongodb的介绍和安装.html">
            
                
                    <a href="../../爬虫提高/4.MONGODB数据库/1.mongodb的介绍和安装.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.4.1.</b>
                        
                        mongodb的介绍和安装
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.4.2" data-path="爬虫提高/4.MONGODB数据库/2.mongodb的权限管理.html">
            
                
                    <a href="../../爬虫提高/4.MONGODB数据库/2.mongodb的权限管理.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.4.2.</b>
                        
                        mongodb的权限管理
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.4.3" data-path="爬虫提高/4.MONGODB数据库/3.mongodb的基本使用.html">
            
                
                    <a href="../../爬虫提高/4.MONGODB数据库/3.mongodb的基本使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.4.3.</b>
                        
                        mongodb的入门使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.4.4" data-path="爬虫提高/4.MONGODB数据库/4.mongodb的聚合操作.html">
            
                
                    <a href="../../爬虫提高/4.MONGODB数据库/4.mongodb的聚合操作.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.4.4.</b>
                        
                        mongodb的聚合操作
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.4.5" data-path="爬虫提高/4.MONGODB数据库/5.mongodb的索引.html">
            
                
                    <a href="../../爬虫提高/4.MONGODB数据库/5.mongodb的索引.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.4.5.</b>
                        
                        mongodb的索引
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.4.6" data-path="爬虫提高/4.MONGODB数据库/6.mongodb的备份恢复与导入导出.html">
            
                
                    <a href="../../爬虫提高/4.MONGODB数据库/6.mongodb的备份恢复与导入导出.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.4.6.</b>
                        
                        mongodb的备份恢复与导入导出
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.4.7" data-path="爬虫提高/4.MONGODB数据库/7.mongodb和python的交互.html">
            
                
                    <a href="../../爬虫提高/4.MONGODB数据库/7.mongodb和python的交互.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.4.7.</b>
                        
                        mongodb和python交互
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.4.8" data-path="爬虫提高/4.MONGODB数据库/8.小结.html">
            
                
                    <a href="../../爬虫提高/4.MONGODB数据库/8.小结.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.4.8.</b>
                        
                        小结
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.5" data-path="爬虫提高/5.scrapy/index.html">
            
                
                    <a href="../../爬虫提高/5.scrapy/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.5.</b>
                        
                        scrapy框架
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.5.1" data-path="爬虫提高/5.scrapy/1.scrapy的基础概念和流程.html">
            
                
                    <a href="../../爬虫提高/5.scrapy/1.scrapy的基础概念和流程.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.5.1.</b>
                        
                        scrapy的基础概念和流程
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.5.2" data-path="爬虫提高/5.scrapy/2.scrapy的入门使用.html">
            
                
                    <a href="../../爬虫提高/5.scrapy/2.scrapy的入门使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.5.2.</b>
                        
                        scrapy的入门使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.5.3" data-path="爬虫提高/5.scrapy/3.scrapy发送翻页请求.html">
            
                
                    <a href="../../爬虫提高/5.scrapy/3.scrapy发送翻页请求.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.5.3.</b>
                        
                        scrapy发送翻页请求
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.5.4" data-path="爬虫提高/5.scrapy/4.scrapy的深入使用.html">
            
                
                    <a href="../../爬虫提高/5.scrapy/4.scrapy的深入使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.5.4.</b>
                        
                        scrapy的深入使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.5.5" data-path="爬虫提高/5.scrapy/5.crawlspider类的使用.html">
            
                
                    <a href="../../爬虫提高/5.scrapy/5.crawlspider类的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.5.5.</b>
                        
                        crawlspider类的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.5.6" data-path="爬虫提高/5.scrapy/6.scrapy中间件.html">
            
                
                    <a href="../../爬虫提高/5.scrapy/6.scrapy中间件.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.5.6.</b>
                        
                        scarpy中间件
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.5.7" data-path="爬虫提高/5.scrapy/7.scrapy模拟登陆.html">
            
                
                    <a href="../../爬虫提高/5.scrapy/7.scrapy模拟登陆.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.5.7.</b>
                        
                        scrapy模拟登陆
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.5.8" data-path="爬虫提高/5.scrapy/9.小结.html">
            
                
                    <a href="../../爬虫提高/5.scrapy/9.小结.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.5.8.</b>
                        
                        小结
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.6" data-path="爬虫提高/6.scrapy_redis/index.html">
            
                
                    <a href="../../爬虫提高/6.scrapy_redis/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.6.</b>
                        
                        scrapy_redis
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.6.1" data-path="爬虫提高/6.scrapy_redis/1.scrapy_redis分布式原理.html">
            
                
                    <a href="../../爬虫提高/6.scrapy_redis/1.scrapy_redis分布式原理.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.6.1.</b>
                        
                        scrapy_redis分布式原理
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.6.2" data-path="爬虫提高/6.scrapy_redis/2.scrapy_redis实现增量式爬虫.html">
            
                
                    <a href="../../爬虫提高/6.scrapy_redis/2.scrapy_redis实现增量式爬虫.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.6.2.</b>
                        
                        scrapy_redis实现增量式爬虫
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.6.3" data-path="爬虫提高/6.scrapy_redis/3.scrapy_redis实现分布式爬虫.html">
            
                
                    <a href="../../爬虫提高/6.scrapy_redis/3.scrapy_redis实现分布式爬虫.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.6.3.</b>
                        
                        scrapy_redis实现分布式爬虫
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.6.4" data-path="爬虫提高/6.scrapy_redis/4.scrapy_redis与scrapy的对比.html">
            
                
                    <a href="../../爬虫提高/6.scrapy_redis/4.scrapy_redis与scrapy的对比.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.6.4.</b>
                        
                        scrapy_redis与scrapy的对比
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.6.5" data-path="爬虫提高/6.scrapy_redis/5.小结.html">
            
                
                    <a href="../../爬虫提高/6.scrapy_redis/5.小结.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.6.5.</b>
                        
                        小结
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.7" data-path="爬虫提高/7.爬虫的部署/index.html">
            
                
                    <a href="../../爬虫提高/7.爬虫的部署/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.7.</b>
                        
                        爬虫的部署
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.7.1" data-path="爬虫提高/7.爬虫的部署/1.scrapyd的使用.html">
            
                
                    <a href="../../爬虫提高/7.爬虫的部署/1.scrapyd的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.7.1.</b>
                        
                        scrapyd的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.7.2" data-path="爬虫提高/7.爬虫的部署/2.pycharm发布代码.html">
            
                
                    <a href="../../爬虫提高/7.爬虫的部署/2.pycharm发布代码.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.7.2.</b>
                        
                        pycharm发布代码
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.7.3" data-path="爬虫提高/7.爬虫的部署/3.crontab实现定时任务.html">
            
                
                    <a href="../../爬虫提高/7.爬虫的部署/3.crontab实现定时任务.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.7.3.</b>
                        
                        crontab实现定时任务
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.7.4" data-path="爬虫提高/7.爬虫的部署/4.小结.html">
            
                
                    <a href="../../爬虫提高/7.爬虫的部署/4.小结.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.7.4.</b>
                        
                        小结
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3" data-path="爬虫框架开发/index.html">
            
                
                    <a href="../../爬虫框架开发/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.</b>
                        
                        爬虫框架开发
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.1" data-path="爬虫框架开发/1.爬虫框架开发分析/index.html">
            
                
                    <a href="../../爬虫框架开发/1.爬虫框架开发分析/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.1.</b>
                        
                        爬虫框架开发分析
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.1.1" data-path="爬虫框架开发/1.爬虫框架开发分析/1.了解框架.html">
            
                
                    <a href="../../爬虫框架开发/1.爬虫框架开发分析/1.了解框架.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.1.1.</b>
                        
                        了解框架
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.1.2" data-path="爬虫框架开发/1.爬虫框架开发分析/2.框架设计思路分析.html">
            
                
                    <a href="../../爬虫框架开发/1.爬虫框架开发分析/2.框架设计思路分析.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.1.2.</b>
                        
                        框架设计思路分析
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.1.3" data-path="爬虫框架开发/1.爬虫框架开发分析/3.框架代码雏形结构.html">
            
                
                    <a href="../../爬虫框架开发/1.爬虫框架开发分析/3.框架代码雏形结构.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.1.3.</b>
                        
                        雏形代码结构
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3.2" data-path="爬虫框架开发/2.框架雏形实现/index.html">
            
                
                    <a href="../../爬虫框架开发/2.框架雏形实现/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.</b>
                        
                        框架雏形实现
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.2.1" data-path="爬虫框架开发/2.框架雏形实现/1.框架雏形--http模块和item模块.html">
            
                
                    <a href="../../爬虫框架开发/2.框架雏形实现/1.框架雏形--http模块和item模块.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.1.</b>
                        
                        http模块和item模块
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.2.2" data-path="爬虫框架开发/2.框架雏形实现/2.框架雏形--核心模块.html">
            
                
                    <a href="../../爬虫框架开发/2.框架雏形实现/2.框架雏形--核心模块.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.2.</b>
                        
                        核心模块
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.2.3" data-path="爬虫框架开发/2.框架雏形实现/3.框架安装.html">
            
                
                    <a href="../../爬虫框架开发/2.框架雏形实现/3.框架安装.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.3.</b>
                        
                        框架安装
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.2.4" data-path="爬虫框架开发/2.框架雏形实现/4.框架运行--main.py.html">
            
                
                    <a href="../../爬虫框架开发/2.框架雏形实现/4.框架运行--main.py.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.4.</b>
                        
                        框架运行
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.2.5" data-path="爬虫框架开发/2.框架雏形实现/5.框架雏形--中间件模块.html">
            
                
                    <a href="../../爬虫框架开发/2.框架雏形实现/5.框架雏形--中间件模块.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.5.</b>
                        
                        中间件
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3.3" data-path="爬虫框架开发/4.框架功能完善/index.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.</b>
                        
                        框架功能完善
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.3.1" data-path="爬虫框架开发/4.框架功能完善/1.框架完善--日志模块使用.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/1.框架完善--日志模块使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.1.</b>
                        
                        日志模块使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3.2" data-path="爬虫框架开发/4.框架功能完善/2.框架完善--配置文件实现.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/2.框架完善--配置文件实现.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.2.</b>
                        
                        配置文件实现
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3.3" data-path="爬虫框架开发/4.框架功能完善/3.框架完善--多爬虫实现之一--多请求.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/3.框架完善--多爬虫实现之一--多请求.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.3.</b>
                        
                        多请求实现
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3.4" data-path="爬虫框架开发/4.框架功能完善/4.框架完善--多爬虫实现之二--多个解析函数.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/4.框架完善--多爬虫实现之二--多个解析函数.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.4.</b>
                        
                        多个解析函数实现
                    </a>
            
            
        </li>
    
        <li class="chapter active" data-level="3.3.5" data-path="爬虫框架开发/4.框架功能完善/5.框架完善--多爬虫实现之三--多爬虫文件.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/5.框架完善--多爬虫实现之三--多爬虫文件.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.5.</b>
                        
                        多爬虫文件实现
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3.6" data-path="爬虫框架开发/4.框架功能完善/6.框架完善--实现多个管道.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/6.框架完善--实现多个管道.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.6.</b>
                        
                        实现多个管道
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3.7" data-path="爬虫框架开发/4.框架功能完善/7.框架完善--实现多个中间件.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/7.框架完善--实现多个中间件.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.7.</b>
                        
                        实现多个中间件
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3.8" data-path="爬虫框架开发/4.框架功能完善/8.框架完善--实现动态模块导入.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/8.框架完善--实现动态模块导入.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.8.</b>
                        
                        实现动态模块导入
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3.9" data-path="爬虫框架开发/4.框架功能完善/9.框架完善--实现请求去重.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/9.框架完善--实现请求去重.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.9.</b>
                        
                        实现请求去重
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3.10" data-path="爬虫框架开发/4.框架功能完善/10.框架完善--使用线程池实现异步以及并发控制.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/10.框架完善--使用线程池实现异步以及并发控制.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.10.</b>
                        
                        使用线程池实现异步以及并发控制
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3.11" data-path="爬虫框架开发/4.框架功能完善/11.框架完善--使用协程池实现异步以及并发控制.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/11.框架完善--使用协程池实现异步以及并发控制.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.11.</b>
                        
                        使用协程池实现异步以及并发控制
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3.4" data-path="爬虫框架开发/5.框架功能升级/index.html">
            
                
                    <a href="../../爬虫框架开发/5.框架功能升级/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.4.</b>
                        
                        框架功能升级
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.4.1" data-path="爬虫框架开发/5.框架功能升级/1.框架升级--分布式爬虫设计原理及其实现.html">
            
                
                    <a href="../../爬虫框架开发/5.框架功能升级/1.框架升级--分布式爬虫设计原理及其实现.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.4.1.</b>
                        
                        分布式爬虫设计原理及其实现
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.4.2" data-path="爬虫框架开发/5.框架功能升级/2.框架升级--增量爬虫设计原理及其实现.html">
            
                
                    <a href="../../爬虫框架开发/5.框架功能升级/2.框架升级--增量爬虫设计原理及其实现.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.4.2.</b>
                        
                        增量爬虫设计原理及其实现
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.4.3" data-path="爬虫框架开发/5.框架功能升级/3.框架升级--断点续爬设计原理及其实现.html">
            
                
                    <a href="../../爬虫框架开发/5.框架功能升级/3.框架升级--断点续爬设计原理及其实现.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.4.3.</b>
                        
                        断点续爬设计原理及其实现
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3.5" data-path="爬虫框架开发/6.项目实战/index.html">
            
                
                    <a href="../../爬虫框架开发/6.项目实战/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.5.</b>
                        
                        项目实战
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.5.1" data-path="爬虫框架开发/6.项目实战/1.案例1-scrapy_plus实现腾讯招聘爬虫.html">
            
                
                    <a href="../../爬虫框架开发/6.项目实战/1.案例1-scrapy_plus实现腾讯招聘爬虫.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.5.1.</b>
                        
                        scrapy_plus实现腾讯招聘爬虫
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.5.2" data-path="爬虫框架开发/6.项目实战/2.案例2-scrapy_plus实现新浪新闻爬虫.html">
            
                
                    <a href="../../爬虫框架开发/6.项目实战/2.案例2-scrapy_plus实现新浪新闻爬虫.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.5.2.</b>
                        
                        scrapy_plus实现新浪滚动新闻爬虫
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="4" data-path="扩展阅读/index.html">
            
                
                    <a href="../../扩展阅读/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.</b>
                        
                        扩展阅读
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="4.1" data-path="扩展阅读/ascii和unicode以及utf-8.html">
            
                
                    <a href="../../扩展阅读/ascii和unicode以及utf-8.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.1.</b>
                        
                        ascii、unicode和utf-8的起源
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.2" data-path="扩展阅读/charles使用指南.html">
            
                
                    <a href="../../扩展阅读/charles使用指南.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.2.</b>
                        
                        charles使用指南
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.3" data-path="扩展阅读/urllib中Handler处理器和自定义Opener.html">
            
                
                    <a href="../../扩展阅读/urllib中Handler处理器和自定义Opener.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.3.</b>
                        
                        urlib的扩展
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.4" data-path="扩展阅读/redis-manger-desktop.html">
            
                
                    <a href="../../扩展阅读/redis-manger-desktop.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.4.</b>
                        
                        redis-desktop-manger的介绍
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.5" data-path="扩展阅读/代理ip检测.html">
            
                
                    <a href="../../扩展阅读/代理ip检测.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.5.</b>
                        
                        代理ip检测
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.6" data-path="扩展阅读/selenium深入拓展.html">
            
                
                    <a href="../../扩展阅读/selenium深入拓展.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.6.</b>
                        
                        selenium深入拓展
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.7" data-path="扩展阅读/docker简单使用.html">
            
                
                    <a href="../../扩展阅读/docker简单使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.7.</b>
                        
                        docker在爬虫中的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.8" data-path="扩展阅读/appium介绍.html">
            
                
                    <a href="../../扩展阅读/appium介绍.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.8.</b>
                        
                        appium介绍
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.9" data-path="扩展阅读/pywin32介绍.html">
            
                
                    <a href="../../扩展阅读/pywin32介绍.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.9.</b>
                        
                        pywin32介绍
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.10" data-path="扩展阅读/百度翻译sign值获取.html">
            
                
                    <a href="../../扩展阅读/百度翻译sign值获取.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.10.</b>
                        
                        百度翻译获取sign值
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.11" data-path="扩展阅读/scrapy中ImagePipeline的使用.html">
            
                
                    <a href="../../扩展阅读/scrapy中ImagePipeline的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.11.</b>
                        
                        scrapy中ImagePipeline的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.12" data-path="扩展阅读/sanic、quart类Flask的异步框架介绍.html">
            
                
                    <a href="../../扩展阅读/sanic、quart类Flask的异步框架介绍.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.12.</b>
                        
                        sanic、quart类Flask的异步框架介绍
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.13" data-path="扩展阅读/了解其他网络请求模块.html">
            
                
                    <a href="../../扩展阅读/了解其他网络请求模块.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.13.</b>
                        
                        了解其他网络请求模块
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.14" data-path="扩展阅读/通过Fiddler进行手机抓包.html">
            
                
                    <a href="../../扩展阅读/通过Fiddler进行手机抓包.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.14.</b>
                        
                        通过Fiddler进行手机抓包
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.15" data-path="扩展阅读/Fiddler抓取https的设置.html">
            
                
                    <a href="../../扩展阅读/Fiddler抓取https的设置.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.15.</b>
                        
                        Fiddler抓取https的设置
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.16" data-path="扩展阅读/12306.html">
            
                
                    <a href="../../扩展阅读/12306.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.16.</b>
                        
                        关于12306抢票
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.17" data-path="扩展阅读/svn和git的使用.html">
            
                
                    <a href="../../扩展阅读/svn和git的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.17.</b>
                        
                        svn和git的使用
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    


            
            <li class="divider"></li>
            <li>
                <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
                    Published with GitBook
                </a>
            </li>
            
        </ul>
    </nav>
</div>

    <div class="book-body">
        <div class="body-inner">
            <div class="book-header" role="navigation">
    <!-- Actions Left -->
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="../../" >传智播客python爬虫课程</a>
    </h1>
</div>

            <div class="page-wrapper" tabindex="-1" role="main">
                <div class="page-inner">
                
                
                    <section class="normal" id="section-">
                    
                        <h2 id="&#x591A;&#x722C;&#x866B;&#x5B9E;&#x73B0;&#x4E4B;&#x4E09;----&#x591A;&#x722C;&#x866B;&#x6587;&#x4EF6;">&#x591A;&#x722C;&#x866B;&#x5B9E;&#x73B0;&#x4E4B;&#x4E09;  --  &#x591A;&#x722C;&#x866B;&#x6587;&#x4EF6;</h2>
<h5 id="&#x5B66;&#x4E60;&#x76EE;&#x6807;">&#x5B66;&#x4E60;&#x76EE;&#x6807;</h5>
<ol>
<li>&#x4F18;&#x5316;&#x73B0;&#x6709;&#x7684;&#x722C;&#x866B;&#x7ED3;&#x6784;&#xFF0C;&#x5B9E;&#x73B0;&#x540C;&#x65F6;&#x5F00;&#x59CB;&#x6267;&#x884C;&#x591A;&#x4E2A;&#x722C;&#x866B;</li>
</ol>
<hr>
<h3 id="1-&#x4E3A;&#x4EC0;&#x4E48;&#x9700;&#x8981;&#x4F18;&#x5316;&#x73B0;&#x6709;&#x7684;&#x722C;&#x866B;&#x7ED3;&#x6784;">1 &#x4E3A;&#x4EC0;&#x4E48;&#x9700;&#x8981;&#x4F18;&#x5316;&#x73B0;&#x6709;&#x7684;&#x722C;&#x866B;&#x7ED3;&#x6784;</h3>
<p>&#x5F53;&#x722C;&#x866B;&#x6BD4;&#x8F83;&#x5C11;&#x7684;&#x65F6;&#x5019;&#xFF0C;&#x6211;&#x4EEC;&#x7684;&#x9879;&#x76EE;&#x7ED3;&#x6784;&#x76F8;&#x5BF9;&#x5408;&#x7406;&#xFF0C;&#x4F46;&#x662F;&#x5F53;&#x8981;&#x6293;&#x53D6;&#x7684;&#x7F51;&#x7AD9;&#x6BD4;&#x8F83;&#x591A;&#x7684;&#x65F6;&#x5019;&#xFF0C;&#x53EF;&#x4EE5;&#x501F;&#x9274;scrapy&#x7684;&#x65B9;&#x6CD5;&#xFF0C;&#x628A;&#x4E0D;&#x540C;&#x7F51;&#x7AD9;&#x7684;&#x722C;&#x866B;&#x5206;&#x522B;&#x5728;&#x4E0D;&#x540C;&#x7684;py&#x6587;&#x4EF6;&#x4E2D;&#x7F16;&#x5199;&#xFF0C;&#x4E4B;&#x540E;&#x653E;&#x5728;&#x4E00;&#x4E2A;&#x76EE;&#x5F55;&#x4E0B;&#xFF1B;&#x540C;&#x65F6;&#xFF0C;&#x6211;&#x4EEC;&#x5F88;&#x591A;&#x65F6;&#x5019;&#x8FD8;&#x5E0C;&#x671B;&#x80FD;&#x591F;&#x6709;&#x540C;&#x65F6;&#x542F;&#x52A8;&#x9879;&#x76EE;&#x4E2D;&#x7684;&#x6240;&#x6709;&#x7684;&#x722C;&#x866B;</p>
<h3 id="2-&#x5C06;&#x591A;&#x4E2A;&#x722C;&#x866B;&#x7C7B;&#x5206;&#x79BB;&#x4E3A;&#x591A;&#x4E2A;&#x722C;&#x866B;&#x6587;&#x4EF6;&#x722C;&#x866B;&#x6587;&#x4EF6;">2 &#x5C06;&#x591A;&#x4E2A;&#x722C;&#x866B;&#x7C7B;&#x5206;&#x79BB;&#x4E3A;&#x591A;&#x4E2A;&#x722C;&#x866B;&#x6587;&#x4EF6;&#x722C;&#x866B;&#x6587;&#x4EF6;</h3>
<p>&#x4E3A;&#x4E86;&#x89E3;&#x8026;&#x5408;&#xFF0C;&#x5E94;&#x5C06;&#x6BCF;&#x4E2A;&#x7AD9;&#x70B9;&#x7684;&#x722C;&#x866B;&#x5199;&#x4E3A;&#x5355;&#x72EC;&#x4E00;&#x4E2A;py&#x6587;&#x4EF6;&#xFF0C;&#x56E0;&#x6B64;&#x66F4;&#x6539;&#x4E00;&#x4E0B;&#x653E;&#x7F6E;&#x722C;&#x866B;&#x7684;&#x6A21;&#x5757;&#xFF0C;&#x7ED3;&#x6784;&#x5982;&#x4E0B;&#xFF1A;</p>
<pre><code>- &#x9879;&#x76EE;&#x6587;&#x4EF6;&#x5939;
  -- main.py
  -- spiders
     -- __init__.py
     -- baidu.py
     -- douban.py
  -- settings.py
</code></pre><p>&#x5176;&#x4E2D;<code>baidu.py</code>&#x548C;<code>douban.py</code>&#x5206;&#x522B;&#x662F;&#x6293;&#x53D6;&#x767E;&#x5EA6;&#x548C;&#x8C46;&#x74E3;&#x7684;&#x722C;&#x866B;&#x6587;&#x4EF6;</p>
<ul>
<li><code>baidu.py</code>:</li>
</ul>
<pre><code class="lang-Python"># project_dir/spiders/baidu.py
from scrapy_plus.core.spider import Spider

# &#x7EE7;&#x627F;&#x6846;&#x67B6;&#x7684;&#x722C;&#x866B;&#x57FA;&#x7C7B;
class BaiduSpider(Spider):

    start_urls = [&apos;http://www.baidu.com&apos;]    # &#x8BBE;&#x7F6E;&#x521D;&#x59CB;&#x8BF7;&#x6C42;url
</code></pre>
<ul>
<li><code>douban.py</code>: &#x6293;&#x53D6;&#x8C46;&#x74E3;&#x7535;&#x5F71;top250&#x7684;&#x5217;&#x8868;&#x9875;&#x4FE1;&#x606F;</li>
</ul>
<pre><code class="lang-python"><span class="token comment" spellcheck="true"># project_dir/spiders/douban.py</span>
<span class="token keyword">from</span> scrapy_plus<span class="token punctuation">.</span>core<span class="token punctuation">.</span>spider <span class="token keyword">import</span> Spider
<span class="token keyword">from</span> scrapy_plus<span class="token punctuation">.</span>http<span class="token punctuation">.</span>request <span class="token keyword">import</span> Request
<span class="token keyword">from</span> scrapy_plus<span class="token punctuation">.</span>item <span class="token keyword">import</span> Item


<span class="token keyword">class</span> <span class="token class-name">DoubanSpider</span><span class="token punctuation">(</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>

    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># &#x91CD;&#x5199;start_requests&#x65B9;&#x6CD5;&#x540E;&#xFF0C;&#x8FD9;&#x4E2A;&#x5C5E;&#x6027;&#x5C31;&#x6CA1;&#x6709;&#x8BBE;&#x7F6E;&#x7684;&#x5FC5;&#x8981;&#x4E86;</span>

    <span class="token keyword">def</span> <span class="token function">start_requests</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># &#x91CD;&#x5199;start_requests&#x65B9;&#x6CD5;&#xFF0C;&#x8FD4;&#x56DE;&#x591A;&#x4E2A;&#x8BF7;&#x6C42;</span>
        base_url <span class="token operator">=</span> <span class="token string">&apos;http://movie.douban.com/top250?start=&apos;</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">250</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># &#x9010;&#x4E2A;&#x8FD4;&#x56DE;&#x7B2C;1-10&#x9875;&#x7684;&#x8BF7;&#x6C42;&#x5C5E;&#x76F8;</span>
            url <span class="token operator">=</span> base_url <span class="token operator">+</span> str<span class="token punctuation">(</span>i<span class="token punctuation">)</span>
            <span class="token keyword">yield</span> Request<span class="token punctuation">(</span>url<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&apos;&apos;&apos;&#x89E3;&#x6790;&#x8C46;&#x74E3;&#x7535;&#x5F71;top250&#x5217;&#x8868;&#x9875;&apos;&apos;&apos;</span>
        title_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token comment" spellcheck="true"># &#x5B58;&#x50A8;&#x6240;&#x6709;&#x7684;</span>
        <span class="token keyword">for</span> li <span class="token keyword">in</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&quot;//ol[@class=&apos;grid_view&apos;]/li&quot;</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># &#x904D;&#x5386;&#x6BCF;&#x4E00;&#x4E2A;li&#x6807;&#x7B7E;</span>
            <span class="token comment" spellcheck="true"># title = li.xpath(&quot;.//span[@class=&apos;title&apos;][1]/text()&quot;)    # &#x63D0;&#x53D6;&#x8BE5;li&#x6807;&#x4E0B;&#x7684; &#x6807;&#x9898;</span>
            <span class="token comment" spellcheck="true"># title_list.append(title[0])</span>
            detail_url <span class="token operator">=</span> li<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&quot;.//div[@class=&apos;info&apos;]/div[@class=&apos;hd&apos;]/a/@href&quot;</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            <span class="token keyword">yield</span> Request<span class="token punctuation">(</span>detail_url<span class="token punctuation">,</span> parse<span class="token operator">=</span><span class="token string">&quot;parse_detail&quot;</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># &#x53D1;&#x8D77;&#x8BE6;&#x60C5;&#x9875;&#x7684;&#x8BF7;&#x6C42;&#xFF0C;&#x5E76;&#x6307;&#x5B9A;&#x89E3;&#x6790;&#x51FD;&#x6570;&#x662F;parse_detail&#x65B9;&#x6CD5;</span>
        <span class="token comment" spellcheck="true"># yield Item(title_list)    # &#x8FD4;&#x56DE;&#x6807;&#x9898;</span>

    <span class="token keyword">def</span> <span class="token function">parse_detail</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&apos;&apos;&apos;&#x89E3;&#x6790;&#x8BE6;&#x60C5;&#x9875;&apos;&apos;&apos;</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&apos;&#x8BE6;&#x60C5;&#x9875;url&#xFF1A;&apos;</span><span class="token punctuation">,</span> response<span class="token punctuation">.</span>url<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># &#x6253;&#x5370;&#x4E00;&#x4E0B;&#x54CD;&#x5E94;&#x7684;url</span>
        <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token comment" spellcheck="true"># &#x7531;&#x4E8E;&#x5FC5;&#x987B;&#x8FD4;&#x56DE;&#x4E00;&#x4E2A;&#x5BB9;&#x5668;&#xFF0C;&#x8FD9;&#x91CC;&#x8FD4;&#x56DE;&#x4E00;&#x4E2A;&#x7A7A;&#x5217;&#x8868;</span>
</code></pre>
<h3 id="3-&#x540C;&#x65F6;&#x6267;&#x884C;&#x591A;&#x4E2A;&#x4E0D;&#x540C;&#x7684;&#x722C;&#x866B;">3 &#x540C;&#x65F6;&#x6267;&#x884C;&#x591A;&#x4E2A;&#x4E0D;&#x540C;&#x7684;&#x722C;&#x866B;</h3>
<p>&#x5982;&#x628A;&#x8C46;&#x74E3;&#x722C;&#x866B;&#x548C;&#x767E;&#x5EA6;&#x722C;&#x866B;&#x4E00;&#x8D77;&#x542F;&#x52A8;&#x5E76;&#x6267;&#x884C;</p>
<p>&#x4F20;&#x5165;&#x5F62;&#x5F0F;&#xFF1A;&#x5E76;&#x7528;&#x5B57;&#x5178;&#x7684;&#x5F62;&#x5F0F;&#x4F20;&#x5165;&#x591A;&#x4E2A;&#x722C;&#x866B;&#xFF1A;</p>
<ul>
<li><code>main.py</code></li>
</ul>
<pre><code class="lang-python"><span class="token comment" spellcheck="true"># project_dir/main.py</span>
<span class="token keyword">from</span> scrapy_plus<span class="token punctuation">.</span>core<span class="token punctuation">.</span>engine <span class="token keyword">import</span> Engine    <span class="token comment" spellcheck="true"># &#x5BFC;&#x5165;&#x5F15;&#x64CE;</span>

<span class="token keyword">from</span> spiders<span class="token punctuation">.</span>baidu <span class="token keyword">import</span> BaiduSpider
<span class="token keyword">from</span> spiders<span class="token punctuation">.</span>douban <span class="token keyword">import</span> DoubanSpider

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">&apos;__main__&apos;</span><span class="token punctuation">:</span>
    baidu_spider <span class="token operator">=</span> BaiduSpider<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># &#x5B9E;&#x4F8B;&#x5316;&#x722C;&#x866B;&#x5BF9;&#x8C61;</span>
    douban_spider <span class="token operator">=</span> DoubanSpider<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># &#x5B9E;&#x4F8B;&#x5316;&#x722C;&#x866B;&#x5BF9;&#x8C61;</span>
    spiders <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&apos;baidu&apos;</span><span class="token punctuation">:</span>baidu_spider<span class="token punctuation">,</span> <span class="token string">&apos;douban&apos;</span><span class="token punctuation">:</span>douban_spider<span class="token punctuation">}</span>
    engine <span class="token operator">=</span> Engine<span class="token punctuation">(</span>spiders<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># &#x4F20;&#x5165;&#x722C;&#x866B;&#x5BF9;&#x8C61;</span>
    engine<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># &#x542F;&#x52A8;&#x5F15;&#x64CE;</span>
</code></pre>
<p>&#x5728;&#x5F15;&#x64CE;&#x4E2D;&#x7528;&#x5230;&#x722C;&#x866B;&#x5BF9;&#x8C61;&#x7684;&#x5730;&#x65B9;&#x90FD;&#x8981;&#x505A;&#x76F8;&#x5E94;&#x7684;&#x4FEE;&#x6539;</p>
<ul>
<li><code>engine.py</code>&#xFF1A;</li>
</ul>
<pre><code class="lang-python"><span class="token triple-quoted-string string">&apos;&apos;&apos;&#x5F15;&#x64CE;
a. &#x5BF9;&#x5916;&#x63D0;&#x4F9B;&#x6574;&#x4E2A;&#x7684;&#x7A0B;&#x5E8F;&#x7684;&#x5165;&#x53E3;
b. &#x4F9D;&#x6B21;&#x8C03;&#x7528;&#x5176;&#x4ED6;&#x7EC4;&#x4EF6;&#x5BF9;&#x5916;&#x63D0;&#x4F9B;&#x7684;&#x63A5;&#x53E3;&#xFF0C;&#x5B9E;&#x73B0;&#x6574;&#x4E2A;&#x6846;&#x67B6;&#x7684;&#x8FD0;&#x4F5C;(&#x9A71;&#x52A8;)
&apos;&apos;&apos;</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token keyword">class</span> <span class="token class-name">Engine</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token comment" spellcheck="true"># &#x6B64;&#x5904;&#x4FEE;&#x6539;</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spiders<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># &#x63A5;&#x6536;&#x5916;&#x90E8;&#x4F20;&#x5165;&#x7684;&#x591A;&#x4E2A;&#x722C;&#x866B;&#x5BF9;&#x8C61;</span>
        self<span class="token punctuation">.</span>spiders <span class="token operator">=</span> spiders    <span class="token comment" spellcheck="true"># &#x722C;&#x866B;&#x5BF9;&#x8C61;</span>

        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>

    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>

    <span class="token keyword">def</span> <span class="token function">_start_requests</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&apos;&apos;&apos;&#x5411;&#x8C03;&#x5EA6;&#x5668;&#x6DFB;&#x52A0;&#x521D;&#x59CB;&#x8BF7;&#x6C42;&apos;&apos;&apos;</span>
        <span class="token comment" spellcheck="true"># 1. &#x722C;&#x866B;&#x6A21;&#x5757;&#x53D1;&#x51FA;&#x521D;&#x59CB;&#x8BF7;&#x6C42;</span>
        <span class="token keyword">for</span> spider_name<span class="token punctuation">,</span> spider <span class="token keyword">in</span> self<span class="token punctuation">.</span>spiders<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment" spellcheck="true"># &#x6B64;&#x5904;&#x65B0;&#x589E;</span>
            <span class="token keyword">for</span> start_request <span class="token keyword">in</span> spider<span class="token punctuation">.</span>start_requests<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment" spellcheck="true"># &#x6B64;&#x5904;&#x4FEE;&#x6539;</span>
                <span class="token comment" spellcheck="true"># 2. &#x628A;&#x521D;&#x59CB;&#x8BF7;&#x6C42;&#x6DFB;&#x52A0;&#x7ED9;&#x8C03;&#x5EA6;&#x5668;</span>
                <span class="token comment" spellcheck="true"># &#x5229;&#x7528;&#x722C;&#x866B;&#x4E2D;&#x95F4;&#x4EF6;&#x9884;&#x5904;&#x7406;&#x8BF7;&#x6C42;&#x5BF9;&#x8C61;</span>
                start_request <span class="token operator">=</span> self<span class="token punctuation">.</span>spider_mid<span class="token punctuation">.</span>process_request<span class="token punctuation">(</span>start_request<span class="token punctuation">)</span>

                <span class="token comment" spellcheck="true"># &#x6B64;&#x5904;&#x65B0;&#x589E;</span>
                <span class="token comment" spellcheck="true"># &#x4E3A;&#x8BF7;&#x6C42;&#x5BF9;&#x8C61;&#x7ED1;&#x5B9A;&#x5B83;&#x6240;&#x5C5E;&#x7684;&#x722C;&#x866B;&#x7684;&#x540D;&#x79F0;</span>
                start_request<span class="token punctuation">.</span>spider_name <span class="token operator">=</span> spider_name   

                self<span class="token punctuation">.</span>scheduler<span class="token punctuation">.</span>add_request<span class="token punctuation">(</span>start_request<span class="token punctuation">)</span>
                <span class="token comment" spellcheck="true"># &#x8BF7;&#x6C42;&#x603B;&#x6570;+1</span>
                self<span class="token punctuation">.</span>total_request_nums <span class="token operator">+=</span> <span class="token number">1</span>

    <span class="token keyword">def</span> <span class="token function">_execute_request_response_item</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&apos;&apos;&apos;&#x6839;&#x636E;&#x8BF7;&#x6C42;&#x3001;&#x53D1;&#x8D77;&#x8BF7;&#x6C42;&#x83B7;&#x53D6;&#x54CD;&#x5E94;&#x3001;&#x89E3;&#x6790;&#x54CD;&#x5E94;&#x3001;&#x5904;&#x7406;&#x54CD;&#x5E94;&#x7ED3;&#x679C;&apos;&apos;&apos;</span>

        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
        <span class="token comment" spellcheck="true"># &#x6B64;&#x5904;&#x65B0;&#x589E;</span>
        <span class="token comment" spellcheck="true"># &#x6839;&#x636E;request&#x7684;spider_name&#x5C5E;&#x6027;&#xFF0C;&#x83B7;&#x53D6;&#x5BF9;&#x5E94;&#x7684;&#x722C;&#x866B;&#x5BF9;&#x8C61;</span>
        spider <span class="token operator">=</span> self<span class="token punctuation">.</span>spiders<span class="token punctuation">[</span>request<span class="token punctuation">.</span>spider_name<span class="token punctuation">]</span>

        <span class="token comment" spellcheck="true"># &#x6B64;&#x5904;&#x4FEE;&#x6539;</span>
        <span class="token comment" spellcheck="true"># &#x83B7;&#x53D6;&#x54CD;&#x5E94;&#x7684;parse&#x65B9;&#x6CD5;</span>
        parse <span class="token operator">=</span> getattr<span class="token punctuation">(</span>spider<span class="token punctuation">,</span> request<span class="token punctuation">.</span>parse<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># getattr(&#x7C7B;, &#x7C7B;&#x4E2D;&#x65B9;&#x6CD5;&#x540D;&#x7684;&#x5B57;&#x7B26;&#x4E32;) = &#x7C7B;&#x65B9;&#x6CD5;&#x5BF9;&#x8C61;</span>

        <span class="token comment" spellcheck="true"># 5. &#x6307;&#x5B9A;&#x7684;&#x89E3;&#x6790;&#x51FD;&#x6570;&#x8FD4;&#x56DE;&#x53EF;&#x8FED;&#x4EE3;&#x5BF9;&#x8C61;</span>
        <span class="token keyword">for</span> result <span class="token keyword">in</span> parse<span class="token punctuation">(</span>response<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># 6.1 &#x5224;&#x65AD;:&#x5982;&#x679C;&#x662F;request&#x5BF9;&#x8C61;</span>
            <span class="token keyword">if</span> isinstance<span class="token punctuation">(</span>result<span class="token punctuation">,</span> Request<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token comment" spellcheck="true"># request&#x7ECF;&#x8FC7;spider&#x4E2D;&#x95F4;&#x4EF6;</span>
                result <span class="token operator">=</span> self<span class="token punctuation">.</span>spider_mid<span class="token punctuation">.</span>process_request<span class="token punctuation">(</span>result<span class="token punctuation">)</span>

                <span class="token comment" spellcheck="true"># &#x6B64;&#x5904;&#x65B0;&#x589E;</span>
                <span class="token comment" spellcheck="true"># &#x7ED9;request&#x5BF9;&#x8C61;&#x589E;&#x52A0;&#x4E00;&#x4E2A;spider_name&#x5C5E;&#x6027;</span>
                result<span class="token punctuation">.</span>spider_name <span class="token operator">=</span> request<span class="token punctuation">.</span>spider_name

                <span class="token comment" spellcheck="true"># &#x5C31;&#x901A;&#x8FC7;add_request()&#x7ED9;&#x8C03;&#x5EA6;&#x5668;&#x7684;&#x961F;&#x5217;</span>
                self<span class="token punctuation">.</span>scheduler<span class="token punctuation">.</span>add_request<span class="token punctuation">(</span>result<span class="token punctuation">)</span>
                <span class="token comment" spellcheck="true"># &#x8BF7;&#x6C42;&#x6570;+1</span>
                self<span class="token punctuation">.</span>total_request_nums <span class="token operator">+=</span> <span class="token number">1</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre>
<p>&#x5B89;&#x88C5;&#x4EE3;&#x7801;&#xFF0C;&#x5E76;&#x8FD0;&#x884C;<code>main.py</code>&#xFF0C;&#x76F4;&#x5230;&#x8C03;&#x8BD5;&#x6210;&#x529F;</p>
<h3 id="4-&#x518D;&#x6B21;&#x6539;&#x8FDB;&#xFF0C;&#x5C06;&#x6BCF;&#x4E2A;&#x722C;&#x866B;&#x7684;&#x540D;&#x79F0;&#x76F4;&#x63A5;&#x8BBE;&#x7F6E;&#x4E3A;&#x722C;&#x866B;&#x7C7B;&#x7684;&#x4E00;&#x4E2A;&#x5C5E;&#x6027;">4 &#x518D;&#x6B21;&#x6539;&#x8FDB;&#xFF0C;&#x5C06;&#x6BCF;&#x4E2A;&#x722C;&#x866B;&#x7684;&#x540D;&#x79F0;&#x76F4;&#x63A5;&#x8BBE;&#x7F6E;&#x4E3A;&#x722C;&#x866B;&#x7C7B;&#x7684;&#x4E00;&#x4E2A;&#x5C5E;&#x6027;</h3>
<p>&#x9879;&#x76EE;&#x4E2D;&#x722C;&#x866B;&#x4EE3;&#x7801;&#x53C2;&#x8003;&#xFF1A;</p>
<pre><code># &#x9879;&#x76EE;&#x8DEF;&#x5F84;/spiders/baidu.py
class BaiduSpider(Spider):
    name = &apos;baidu&apos;    # &#x4E3A;&#x722C;&#x866B;&#x547D;&#x540D;
    ......

# &#x9879;&#x76EE;&#x8DEF;&#x5F84;/spiders/douban.py
class DoubanSpider(Spider):
    name = &apos;douban&apos;  # &#x4E3A;&#x722C;&#x866B;&#x547D;&#x540D;
    ......

# &#x9879;&#x76EE;&#x8DEF;&#x5F84;/main.py
......
if __name__ == &apos;__main__&apos;:
    baidu_spider = BaiduSpider()    # &#x5B9E;&#x4F8B;&#x5316;&#x722C;&#x866B;&#x5BF9;&#x8C61;
    douban_spider = DoubanSpider()    # &#x5B9E;&#x4F8B;&#x5316;&#x722C;&#x866B;&#x5BF9;&#x8C61;
    &apos;&apos;&apos;&#x90A3;&#x4E48;&#x5728;main.py&#x4E2D;&#x5C31;&#x53EF;&#x4EE5;&#x6309;&#x7167;&#x8FD9;&#x6837;&#x7684;&#x65B9;&#x5F0F;&#x8BBE;&#x5B9A;key&#x503C;&apos;&apos;&apos;
    spiders = {BaiduSpider.name: baidu_spider, DoubanSpider.name: douban_spider}
    engine = Engine(spiders)    # &#x4F20;&#x5165;&#x722C;&#x866B;&#x5BF9;&#x8C61;
    engine.start()    # &#x542F;&#x52A8;&#x5F15;&#x64CE;
</code></pre><h5 id="41-&#x76F8;&#x5E94;&#x7684;&#x53BB;&#x4FEE;&#x6539;scrapyplus&#x4E2D;&#x7684;spiderpy">4.1 &#x76F8;&#x5E94;&#x7684;&#x53BB;&#x4FEE;&#x6539;scrapy_plus&#x4E2D;&#x7684;spider.py</h5>
<pre><code class="lang-python">scrapy_plus<span class="token operator">/</span>core<span class="token operator">/</span>spider<span class="token punctuation">.</span>py
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>

<span class="token keyword">class</span> <span class="token class-name">Spider</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&apos;&apos;&apos;
    1. &#x6784;&#x5EFA;&#x8BF7;&#x6C42;&#x4FE1;&#x606F;(&#x521D;&#x59CB;&#x7684;)&#xFF0C;&#x4E5F;&#x5C31;&#x662F;&#x751F;&#x6210;&#x8BF7;&#x6C42;&#x5BF9;&#x8C61;(Request)
    2. &#x89E3;&#x6790;&#x54CD;&#x5E94;&#x5BF9;&#x8C61;&#xFF0C;&#x8FD4;&#x56DE;&#x6570;&#x636E;&#x5BF9;&#x8C61;(Item)&#x6216;&#x8005;&#x65B0;&#x7684;&#x8BF7;&#x6C42;&#x5BF9;&#x8C61;(Request)
    &apos;&apos;&apos;</span>

    name <span class="token operator">=</span> <span class="token string">&apos;&apos;</span> <span class="token comment" spellcheck="true"># &#x6B64;&#x5904;&#x65B0;&#x589E;</span>

    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre>
<hr>
<h3 id="&#x5C0F;&#x7ED3;">&#x5C0F;&#x7ED3;</h3>
<ol>
<li>&#x5B8C;&#x6210;&#x5BF9;&#x73B0;&#x6709;&#x7684;&#x9879;&#x76EE;&#x7ED3;&#x6784;&#x7684;&#x66F4;&#x6539;</li>
<li>&#x5B8C;&#x6210;&#x5BF9;&#x722C;&#x866B;&#x548C;&#x5F15;&#x64CE;&#x7684;&#x4EE3;&#x7801;&#x7684;&#x4FEE;&#x6539;</li>
</ol>
<hr>
<h3 id="&#x672C;&#x5C0F;&#x7ED3;&#x6D89;&#x53CA;&#x4FEE;&#x6539;&#x7684;&#x5B8C;&#x6574;&#x4EE3;&#x7801;">&#x672C;&#x5C0F;&#x7ED3;&#x6D89;&#x53CA;&#x4FEE;&#x6539;&#x7684;&#x5B8C;&#x6574;&#x4EE3;&#x7801;</h3>
<p>&#x9879;&#x76EE;&#x8DEF;&#x5F84;/main.py</p>
<pre><code>from scrapy_plus.core.engine import Engine    # &#x5BFC;&#x5165;&#x5F15;&#x64CE;

from spiders.baidu import BaiduSpider
from spiders.douban import DoubanSpider

if __name__ == &apos;__main__&apos;:
    baidu_spider = BaiduSpider()    # &#x5B9E;&#x4F8B;&#x5316;&#x722C;&#x866B;&#x5BF9;&#x8C61;
    douban_spider = DoubanSpider()    # &#x5B9E;&#x4F8B;&#x5316;&#x722C;&#x866B;&#x5BF9;&#x8C61;
    spiders = {BaiduSpider.name: baidu_spider, DoubanSpider.name: douban_spider}
    engine = Engine(spiders)    # &#x4F20;&#x5165;&#x722C;&#x866B;&#x5BF9;&#x8C61;
    engine.start()    # &#x542F;&#x52A8;&#x5F15;&#x64CE;
</code></pre><p>&#x9879;&#x76EE;&#x8DEF;&#x5F84;/baidu.py</p>
<pre><code>from scrapy_plus.core.spider import Spider

# &#x7EE7;&#x627F;&#x6846;&#x67B6;&#x7684;&#x722C;&#x866B;&#x57FA;&#x7C7B;
class BaiduSpider(Spider):
    name = &apos;baidu&apos;

    start_urls = [&apos;http://www.baidu.com&apos;]    # &#x8BBE;&#x7F6E;&#x521D;&#x59CB;&#x8BF7;&#x6C42;url
</code></pre><p>&#x9879;&#x76EE;&#x8DEF;&#x5F84;/douban.py</p>
<pre><code>
from scrapy_plus.core.spider import Spider
from scrapy_plus.http.request import Request
from scrapy_plus.item import Item


class DoubanSpider(Spider):

    name = &apos;douban&apos;

    start_urls = []  # &#x91CD;&#x5199;start_requests&#x65B9;&#x6CD5;&#x540E;&#xFF0C;&#x8FD9;&#x4E2A;&#x5C5E;&#x6027;&#x5C31;&#x6CA1;&#x6709;&#x8BBE;&#x7F6E;&#x7684;&#x5FC5;&#x8981;&#x4E86;

    def start_requests(self):
        # &#x91CD;&#x5199;start_requests&#x65B9;&#x6CD5;&#xFF0C;&#x8FD4;&#x56DE;&#x591A;&#x4E2A;&#x8BF7;&#x6C42;
        base_url = &apos;http://movie.douban.com/top250?start=&apos;
        for i in range(0, 250, 25):    # &#x9010;&#x4E2A;&#x8FD4;&#x56DE;&#x7B2C;1-10&#x9875;&#x7684;&#x8BF7;&#x6C42;&#x5C5E;&#x76F8;
            url = base_url + str(i)
            yield Request(url)

    def parse(self, response):
        &apos;&apos;&apos;&#x89E3;&#x6790;&#x8C46;&#x74E3;&#x7535;&#x5F71;top250&#x5217;&#x8868;&#x9875;&apos;&apos;&apos;
        title_list = []    # &#x5B58;&#x50A8;&#x6240;&#x6709;&#x7684;
        for li in response.xpath(&quot;//ol[@class=&apos;grid_view&apos;]/li&quot;):    # &#x904D;&#x5386;&#x6BCF;&#x4E00;&#x4E2A;li&#x6807;&#x7B7E;
            # title = li.xpath(&quot;.//span[@class=&apos;title&apos;][1]/text()&quot;)    # &#x63D0;&#x53D6;&#x8BE5;li&#x6807;&#x4E0B;&#x7684; &#x6807;&#x9898;
            # title_list.append(title[0])
            detail_url = li.xpath(&quot;.//div[@class=&apos;info&apos;]/div[@class=&apos;hd&apos;]/a/@href&quot;)[0]
            yield Request(detail_url, parse=&quot;parse_detail&quot;)    # &#x53D1;&#x8D77;&#x8BE6;&#x60C5;&#x9875;&#x7684;&#x8BF7;&#x6C42;&#xFF0C;&#x5E76;&#x6307;&#x5B9A;&#x89E3;&#x6790;&#x51FD;&#x6570;&#x662F;parse_detail&#x65B9;&#x6CD5;
        # yield Item(title_list)    # &#x8FD4;&#x56DE;&#x6807;&#x9898;

    def parse_detail(self, response):
        &apos;&apos;&apos;&#x89E3;&#x6790;&#x8BE6;&#x60C5;&#x9875;&apos;&apos;&apos;
        print(&apos;&#x8BE6;&#x60C5;&#x9875;url&#xFF1A;&apos;, response.url)    # &#x6253;&#x5370;&#x4E00;&#x4E0B;&#x54CD;&#x5E94;&#x7684;url
        yield {&apos;url&apos;: response.url}   # &#x8FED;&#x4EE3;&#x8FD4;&#x56DE;item
</code></pre><p>scrapy_plus/core/engine.py</p>
<pre><code>&apos;&apos;&apos;&#x5F15;&#x64CE;&#x7EC4;&#x4EF6;&apos;&apos;&apos;
from scrapy_plus.http.request import Request    # &#x5BFC;&#x5165;Request&#x5BF9;&#x8C61;

from .scheduler import Scheduler
from .downloader import Downloader
from .pipeline import Pipeline
from .spider import Spider

from scrapy_plus.middlewares.spider_middlewares import SpiderMiddleware
from scrapy_plus.middlewares.downloader_middlewares import DownloaderMiddleware

from datetime import datetime
from scrapy_plus.utils.log import logger    # &#x5BFC;&#x5165;logger

import time


class Engine(object):
    &apos;&apos;&apos;
    a. &#x5BF9;&#x5916;&#x63D0;&#x4F9B;&#x6574;&#x4E2A;&#x7684;&#x7A0B;&#x5E8F;&#x7684;&#x5165;&#x53E3;
    b. &#x4F9D;&#x6B21;&#x8C03;&#x7528;&#x5176;&#x4ED6;&#x7EC4;&#x4EF6;&#x5BF9;&#x5916;&#x63D0;&#x4F9B;&#x7684;&#x63A5;&#x53E3;&#xFF0C;&#x5B9E;&#x73B0;&#x6574;&#x4E2A;&#x6846;&#x67B6;&#x7684;&#x8FD0;&#x4F5C;(&#x9A71;&#x52A8;)
    &apos;&apos;&apos;

    def __init__(self, spiders):
        self.spiders = spiders   # &#x63A5;&#x6536;&#x722C;&#x866B;&#x5B57;&#x5178;
        self.scheduler = Scheduler()    # &#x521D;&#x59CB;&#x5316;&#x8C03;&#x5EA6;&#x5668;&#x5BF9;&#x8C61;
        self.downloader = Downloader()    # &#x521D;&#x59CB;&#x5316;&#x4E0B;&#x8F7D;&#x5668;&#x5BF9;&#x8C61;
        self.pipeline = Pipeline()    # &#x521D;&#x59CB;&#x5316;&#x7BA1;&#x9053;&#x5BF9;&#x8C61;

        self.spider_mid = SpiderMiddleware()    # &#x521D;&#x59CB;&#x5316;&#x722C;&#x866B;&#x4E2D;&#x95F4;&#x4EF6;&#x5BF9;&#x8C61;
        self.downloader_mid = DownloaderMiddleware()    # &#x521D;&#x59CB;&#x5316;&#x4E0B;&#x8F7D;&#x5668;&#x4E2D;&#x95F4;&#x4EF6;&#x5BF9;&#x8C61;

        self.total_request_nums = 0
        self.total_response_nums = 0

    def start(self):
        &apos;&apos;&apos;&#x542F;&#x52A8;&#x6574;&#x4E2A;&#x5F15;&#x64CE;&apos;&apos;&apos;
        start_time = datetime.now()  # &#x8D77;&#x59CB;&#x65F6;&#x95F4;
        logger.info(&quot;&#x5F00;&#x59CB;&#x8FD0;&#x884C;&#x65F6;&#x95F4;&#xFF1A;%s&quot; % start_time)  # &#x4F7F;&#x7528;&#x65E5;&#x5FD7;&#x8BB0;&#x5F55;&#x8D77;&#x59CB;&#x8FD0;&#x884C;&#x65F6;&#x95F4;
        self._start_engine()
        stop = datetime.now()  # &#x7ED3;&#x675F;&#x65F6;&#x95F4;
        end_time = datetime.now()
        logger.info(&quot;&#x722C;&#x866B;&#x7ED3;&#x675F;&#xFF1A;{}&quot;.format(end_time))
        logger.info(&quot;&#x722C;&#x866B;&#x4E00;&#x5171;&#x8FD0;&#x884C;&#xFF1A;{}&#x79D2;&quot;.format((end_time-start_time).total_seconds()))
        logger.info(&quot;&#x603B;&#x7684;&#x8BF7;&#x6C42;&#x6570;&#x91CF;:{}&quot;.format(self.total_request_nums))
        logger.info(&quot;&#x603B;&#x7684;&#x54CD;&#x5E94;&#x6570;&#x91CF;:{}&quot;.format(self.total_response_nums))

    def _start_request(self):
        for spider_name, spider in self.spiders.items():
            for start_request in spider.start_requests():
                #1. &#x5BF9;start_request&#x8FDB;&#x8FC7;&#x722C;&#x866B;&#x4E2D;&#x95F4;&#x4EF6;&#x8FDB;&#x884C;&#x5904;&#x7406;
                start_request = self.spider_mid.process_request(start_request)

                # &#x4E3A;&#x8BF7;&#x6C42;&#x5BF9;&#x8C61;&#x7ED1;&#x5B9A;&#x5B83;&#x6240;&#x5C5E;&#x7684;&#x722C;&#x866B;&#x7684;&#x540D;&#x79F0;
                start_request.spider_name = spider_name

                #2. &#x8C03;&#x7528;&#x8C03;&#x5EA6;&#x5668;&#x7684;add_request&#x65B9;&#x6CD5;&#xFF0C;&#x6DFB;&#x52A0;request&#x5BF9;&#x8C61;&#x5230;&#x8C03;&#x5EA6;&#x5668;&#x4E2D;
                self.scheduler.add_request(start_request)
                #&#x8BF7;&#x6C42;&#x6570;+1
                self.total_request_nums += 1

    def _execute_request_response_item(self):
        &apos;&apos;&apos;&#x6839;&#x636E;&#x8BF7;&#x6C42;&#x3001;&#x53D1;&#x8D77;&#x8BF7;&#x6C42;&#x83B7;&#x53D6;&#x54CD;&#x5E94;&#x3001;&#x89E3;&#x6790;&#x54CD;&#x5E94;&#x3001;&#x5904;&#x7406;&#x54CD;&#x5E94;&#x7ED3;&#x679C;&apos;&apos;&apos;
        #3. &#x8C03;&#x7528;&#x8C03;&#x5EA6;&#x5668;&#x7684;get_request&#x65B9;&#x6CD5;&#xFF0C;&#x83B7;&#x53D6;request&#x5BF9;&#x8C61;
        request = self.scheduler.get_request()
        if request is None: #&#x5982;&#x679C;&#x6CA1;&#x6709;&#x83B7;&#x53D6;&#x5230;&#x8BF7;&#x6C42;&#x5BF9;&#x8C61;&#xFF0C;&#x76F4;&#x63A5;&#x8FD4;&#x56DE;
            return

        #request&#x5BF9;&#x8C61;&#x7ECF;&#x8FC7;&#x4E0B;&#x8F7D;&#x5668;&#x4E2D;&#x95F4;&#x4EF6;&#x7684;process_request&#x8FDB;&#x884C;&#x5904;&#x7406;
        request = self.downloader_mid.process_request(request)

        #4. &#x8C03;&#x7528;&#x4E0B;&#x8F7D;&#x5668;&#x7684;get_response&#x65B9;&#x6CD5;&#xFF0C;&#x83B7;&#x53D6;&#x54CD;&#x5E94;
        response = self.downloader.get_response(request)

        response.meta = request.meta

        #response&#x5BF9;&#x8C61;&#x7ECF;&#x8FC7;&#x4E0B;&#x8F7D;&#x5668;&#x4E2D;&#x95F4;&#x4EF6;&#x7684;process_response&#x8FDB;&#x884C;&#x5904;&#x7406;
        response = self.downloader_mid.process_response(response)
        #response&#x5BF9;&#x8C61;&#x7ECF;&#x8FC7;&#x4E0B;&#x722C;&#x866B;&#x4E2D;&#x95F4;&#x4EF6;&#x7684;process_response&#x8FDB;&#x884C;&#x5904;&#x7406;
        response = self.spider_mid.process_response(response)

        # &#x6839;&#x636E;request&#x7684;spider_name&#x5C5E;&#x6027;&#xFF0C;&#x83B7;&#x53D6;&#x5BF9;&#x5E94;&#x7684;&#x722C;&#x866B;&#x5BF9;&#x8C61;
        spider = self.spiders[request.spider_name]
        # parse&#x65B9;&#x6CD5;
        parse = getattr(spider, request.parse)  # getattr(&#x7C7B;, &#x7C7B;&#x4E2D;&#x65B9;&#x6CD5;&#x540D;&#x7684;&#x5B57;&#x7B26;&#x4E32;) = &#x7C7B;&#x65B9;&#x6CD5;&#x5BF9;&#x8C61;

        #5. &#x8C03;&#x7528;&#x722C;&#x866B;&#x7684;parse&#x65B9;&#x6CD5;&#xFF0C;&#x5904;&#x7406;&#x54CD;&#x5E94;
        for result in parse(response):
            #6.&#x5224;&#x65AD;&#x7ED3;&#x679C;&#x7684;&#x7C7B;&#x578B;&#xFF0C;&#x5982;&#x679C;&#x662F;request&#xFF0C;&#x91CD;&#x65B0;&#x8C03;&#x7528;&#x8C03;&#x5EA6;&#x5668;&#x7684;add_request&#x65B9;&#x6CD5;
            if isinstance(result,Request):
                #&#x5728;&#x89E3;&#x6790;&#x51FD;&#x6570;&#x5F97;&#x5230;request&#x5BF9;&#x8C61;&#x4E4B;&#x540E;&#xFF0C;&#x4F7F;&#x7528;process_request&#x8FDB;&#x884C;&#x5904;&#x7406;
                result = self.spider_mid.process_request(result)

                # &#x7ED9;request&#x5BF9;&#x8C61;&#x589E;&#x52A0;&#x4E00;&#x4E2A;spider_name&#x5C5E;&#x6027;
                result.spider_name = request.spider_name

                self.scheduler.add_request(result)
                self.total_request_nums += 1
            #7&#x5982;&#x679C;&#x4E0D;&#x662F;&#xFF0C;&#x8C03;&#x7528;pipeline&#x7684;process_item&#x65B9;&#x6CD5;&#x5904;&#x7406;&#x7ED3;&#x679C;
            else:
                self.pipeline.process_item(result)

        self.total_response_nums += 1

    def _start_engine(self):
        &apos;&apos;&apos;
        &#x5177;&#x4F53;&#x7684;&#x5B9E;&#x73B0;&#x5F15;&#x64CE;&#x7684;&#x7EC6;&#x8282;
        :return:
        &apos;&apos;&apos;
        self._start_request()
        while True:
            time.sleep(0.001)
            self._execute_request_response_item()
            if self.total_response_nums&gt;= self.total_request_nums:
                break
</code></pre><p>scrapy_plus/core/spider.py</p>
<pre><code>&apos;&apos;&apos;&#x722C;&#x866B;&#x7EC4;&#x4EF6;&#x5C01;&#x88C5;&apos;&apos;&apos;
from scrapy_plus.item import Item    # &#x5BFC;&#x5165;Item&#x5BF9;&#x8C61;
from scrapy_plus.http.request import Request    # &#x5BFC;&#x5165;Request&#x5BF9;&#x8C61;


class Spider(object):
    &apos;&apos;&apos;
    1. &#x6784;&#x5EFA;&#x8BF7;&#x6C42;&#x4FE1;&#x606F;(&#x521D;&#x59CB;&#x7684;)&#xFF0C;&#x4E5F;&#x5C31;&#x662F;&#x751F;&#x6210;&#x8BF7;&#x6C42;&#x5BF9;&#x8C61;(Request)
    2. &#x89E3;&#x6790;&#x54CD;&#x5E94;&#x5BF9;&#x8C61;&#xFF0C;&#x8FD4;&#x56DE;&#x6570;&#x636E;&#x5BF9;&#x8C61;(Item)&#x6216;&#x8005;&#x65B0;&#x7684;&#x8BF7;&#x6C42;&#x5BF9;&#x8C61;(Request)
    &apos;&apos;&apos;

    name = &apos;&apos;

    start_urls = []

    # &#x5229;&#x7528;&#x751F;&#x6210;&#x5668;&#x65B9;&#x5F0F;&#x5B9E;&#x73B0;&#xFF0C;&#x63D0;&#x9AD8;&#x7A0B;&#x5E8F;&#x7684;&#x8D44;&#x6E90;&#x6D88;&#x8017;
    def start_requests(self):
        &apos;&apos;&apos;&#x6784;&#x5EFA;&#x521D;&#x59CB;&#x8BF7;&#x6C42;&#x5BF9;&#x8C61;&#x5E76;&#x8FD4;&#x56DE;&apos;&apos;&apos;
        for url in self.start_urls:
            yield Request(url)

    def parse(self, response):
        &apos;&apos;&apos;&#x89E3;&#x6790;&#x8BF7;&#x6C42;
        &#x5E76;&#x8FD4;&#x56DE;&#x65B0;&#x7684;&#x8BF7;&#x6C42;&#x5BF9;&#x8C61;&#x3001;&#x6216;&#x8005;&#x6570;&#x636E;&#x5BF9;&#x8C61;
        &#x8FD4;&#x56DE;&#x503C;&#x5E94;&#x5F53;&#x662F;&#x4E00;&#x4E2A;&#x5BB9;&#x5668;&#xFF0C;&#x5982;start_requests&#x8FD4;&#x56DE;&#x503C;&#x65B9;&#x6CD5;&#x4E00;&#x6837;&#xFF0C;&#x6539;&#x4E3A;&#x751F;&#x6210;&#x5668;&#x5373;&#x53EF;
        &apos;&apos;&apos;
        yield Item(response.body)   # &#x8FD4;&#x56DE;item&#x5BF9;&#x8C61; &#x6539;&#x4E3A;&#x751F;&#x6210;&#x5668;&#x5373;&#x53EF;
</code></pre>
                    
                    </section>
                
                
                </div>
            </div>
        </div>

        
        <a href="../../爬虫框架开发/4.框架功能完善/4.框架完善--多爬虫实现之二--多个解析函数.html" class="navigation navigation-prev " aria-label="Previous page: 多个解析函数实现"><i class="fa fa-angle-left"></i></a>
        
        
        <a href="../../爬虫框架开发/4.框架功能完善/6.框架完善--实现多个管道.html" class="navigation navigation-next " aria-label="Next page: 实现多个管道"><i class="fa fa-angle-right"></i></a>
        
    </div>
</div>

        
<script src="../../gitbook/app.js"></script>

    
    <script src="../../gitbook/plugins/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.js"></script>
    

    
    <script src="../../gitbook/plugins/gitbook-plugin-book-summary-scroll-position-saver/book-summary-scroll-position-saver.js"></script>
    

    
    <script src="../../gitbook/plugins/gitbook-plugin-search/lunr.min.js"></script>
    

    
    <script src="../../gitbook/plugins/gitbook-plugin-search/search.js"></script>
    

    
    <script src="../../gitbook/plugins/gitbook-plugin-sharing/buttons.js"></script>
    

    
    <script src="../../gitbook/plugins/gitbook-plugin-fontsettings/buttons.js"></script>
    

<script>
require(["gitbook"], function(gitbook) {
    var config = {"expandable-chapters-small":{},"prism":{"css":["prismjs/themes/prism-solarizedlight.css"]},"emphasize":{},"book-summary-scroll-position-saver":{},"search":{"maxIndexSize":1000000},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2}};
    gitbook.start(config);
});
</script>

        
    </body>
    
</html>
